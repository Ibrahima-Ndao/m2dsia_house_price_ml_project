import click
import logging
import time
import os
import joblib
import requests
from pipelines.deployment_pipeline import (
    continuous_deployment_pipeline,
    inference_pipeline,
)
from rich import print


@click.command()
@click.option(
    "--stop-service",
    is_flag=True,
    default=False,
    help="Stop the prediction service when done",
)
@click.option(
    "--run-inference",
    is_flag=True,
    default=False,
    help="Run batch inference pipeline",
)
@click.option(
    "--deploy-only",
    is_flag=True,
    default=False,
    help="Only deploy without training (use existing model)",
)
def run_main(stop_service: bool, run_inference: bool, deploy_only: bool):
    """Run the prices predictor deployment pipeline"""
    
    model_name = "prices_predictor"
    
    print(f"üöÄ Starting {model_name} deployment pipeline...")
    
    if stop_service:
        print("üõë Stopping prediction service...")
        try:
            # Try to gracefully shutdown the service
            response = requests.get("http://localhost:5000/health", timeout=5)
            if response.status_code == 200:
                print("‚úÖ Service is running. Note: Manual shutdown required (Ctrl+C)")
            else:
                print("‚ùå Service not responding")
        except requests.exceptions.RequestException:
            print("‚ùå No service found running on port 5000")
        return

    if run_inference:
        print("üîç Running batch inference pipeline...")
        predictions = inference_pipeline()
        if predictions is not None:
            print("‚úÖ Batch inference completed successfully!")
        else:
            print("‚ùå Batch inference failed!")
        return

    if deploy_only:
        print("üì¶ Deploying existing model...")
        try:
            # Check if there's a trained model
            with open("models/latest_model_path.txt", 'r') as f:
                model_path = f.read().strip()
            
            if not os.path.exists(model_path):
                print("‚ùå No trained model found. Please train a model first.")
                return
            
            # Deploy the existing model
            from pipelines.deployment_pipeline import SimpleDeploymentService
            deployment_service = SimpleDeploymentService(model_path, port=5000)
            deployment_service.start()
            
            # Save deployment info
            deployment_info = {
                'model_path': model_path,
                'service_port': 5000,
                'service_url': 'http://localhost:5000',
                'status': 'deployed'
            }
            
            deployment_path = "models/deployment_info.pkl"
            joblib.dump(deployment_info, deployment_path)
            
            print("‚úÖ Model deployed successfully!")
            print("üåê Service available at: http://localhost:5000")
            print("üìã Endpoints:")
            print("   - POST /predict : Make predictions")
            print("   - GET /health  : Health check")
            
            # Keep the service running
            try:
                print("üîÑ Service is running... Press Ctrl+C to stop")
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                print("\nüõë Shutting down...")
                deployment_service.stop()
            
        except FileNotFoundError:
            print("‚ùå No trained model found. Please train a model first.")
        except Exception as e:
            print(f"‚ùå Deployment failed: {e}")
        return

    # Run the full continuous deployment pipeline
    print("üèÉ‚Äç‚ôÇÔ∏è Running continuous deployment pipeline...")
    
    try:
        deployment_service = continuous_deployment_pipeline()
        
        print("‚úÖ Deployment pipeline completed successfully!")
        print("üåê Model service is now running at: http://localhost:5000")
        print("üìã Available endpoints:")
        print("   - POST /predict : Make predictions")
        print("   - GET /health  : Health check")
        
        # Test the service
        print("üß™ Testing the deployed service...")
        try:
            response = requests.get("http://localhost:5000/health", timeout=10)
            if response.status_code == 200:
                print("‚úÖ Service health check passed!")
                
                # Example prediction test
                test_data = {
                    'date':['2014-05-02'],
                    'bedrooms':[2],
                    'bathrooms':[1],
                    'sqft_living':[2570],
                    'sqft_lot':[10193],
                    'floors':[2],
                    'waterfront':[0],
                    'view':[4],
                    'condition':[5],
                    'sqft_above':[2170],
                    'sqft_basement':[0],
                    'yr_built':[1910],
                    'yr_renovated':[0],
                    'street':['West 9th Street'],
                    'city':['New York'],
                    'statezip':['NY 10011'],
                    'country':['USA']
                }
                
                pred_response = requests.post(
                    "http://localhost:5000/predict",
                    json=test_data,
                    timeout=10
                )
                
                if pred_response.status_code == 200:
                    result = pred_response.json()
                    print("‚úÖ Test prediction successful!")
                    print(f"   Sample prediction: {result['predictions'][0]:.2f}")
                else:
                    print("‚ö†Ô∏è  Test prediction failed")
                    
            else:
                print("‚ùå Service health check failed")
                
        except requests.exceptions.RequestException as e:
            print(f"‚ö†Ô∏è  Could not test service: {e}")
        
        # Keep the service running
        print("\nüîÑ Service is running... Press Ctrl+C to stop")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            print("\nüõë Shutting down...")
            deployment_service.stop()
            
    except Exception as e:
        print(f"‚ùå Deployment pipeline failed: {e}")
        logging.error(f"Deployment pipeline error: {e}", exc_info=True)


@click.command()
def test_service():
    """Test the deployed model service."""
    
    print("üß™ Testing deployed model service...")
    
    try:
        # Health check
        response = requests.get("http://localhost:5000/health", timeout=5)
        if response.status_code == 200:
            print("‚úÖ Service is healthy!")
        else:
            print("‚ùå Service health check failed")
            return
        
        # Test prediction
        test_data = {
            'date':['2014-05-02'],
            'bedrooms':[3],
            'bathrooms':[2],
            'sqft_living':[1180],
            'sqft_lot':[5650],
            'floors':[1],
            'waterfront':[0],
            'view':[0],
            'condition':[3],
            'sqft_above':[1180],
            'sqft_basement':[0],
            'yr_built':[2003],
            'yr_renovated':[0],
            'street':['Northwest 105th Street'],
            'city':['Seattle'],
            'statezip':['WA 98105'],
            'country':['USA']
        }
        
        pred_response = requests.post(
            "http://localhost:5000/predict",
            json=test_data,
            timeout=10
        )
        
        if pred_response.status_code == 200:
            result = pred_response.json()
            print("‚úÖ Prediction successful!")
            print(f"   Predicted price: ${result['predictions'][0]:,.2f}")
        else:
            print("‚ùå Prediction failed")
            print(f"   Error: {pred_response.text}")
            
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Could not connect to service: {e}")
        print("   Make sure the service is running on http://localhost:5000")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO, 
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    )
    run_main()